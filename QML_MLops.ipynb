{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Part 1: Set up and data preparation"
      ],
      "metadata": {
        "id": "C6A6KM0_dlKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "rHjqzeSNalqE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply transformations to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with mean and std for MNIST\n",
        "])"
      ],
      "metadata": {
        "id": "geRZpFpHaoPB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "mnist_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3QThRDyasLq",
        "outputId": "64b4dbc6-1c95-42e3-e249-c37caf5bb3ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 15942181.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 480920.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1323992.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4387500.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract data and targets from the dataset\n",
        "X = mnist_dataset.data  # Shape will be [60000, 28, 28] for images\n",
        "y = mnist_dataset.targets  # Shape will be [60000] for labels"
      ],
      "metadata": {
        "id": "KPFaDq8vavfJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the images to be of shape [60000, 784]\n",
        "X = X.view(X.size(0), -1).float()  # Reshape to [60000, 784]"
      ],
      "metadata": {
        "id": "iFv_14QlayyJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uFI-P_OUa03b"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: Model Building\n",
        "# Defining a logistic regression model using PyTorch\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "s50TY77qa4gg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting input and output dimensions\n",
        "input_dim = 28 * 28  # MNIST images are 28x28\n",
        "output_dim = 10      # There are 10 classes (digits 0-9)"
      ],
      "metadata": {
        "id": "7KNt52i4a7l9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the logistic regression model\n",
        "model = LogisticRegressionModel(input_dim, output_dim)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz4rWYJ2a9j9",
        "outputId": "0e830d1c-ca46-40da-b370-f39adf580f95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionModel(\n",
              "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "7jfVj19rbBzf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Training the Model\n",
        "# Training the logistic regression model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print loss every epoch\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saa_WBRObGLU",
        "outputId": "4de7dc25-97a3-4bbd-a100-0e757d5b092a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 82.8287\n",
            "Epoch [2/10], Loss: 2248.7529\n",
            "Epoch [3/10], Loss: 3269.5710\n",
            "Epoch [4/10], Loss: 2794.2476\n",
            "Epoch [5/10], Loss: 2761.1138\n",
            "Epoch [6/10], Loss: 3335.0125\n",
            "Epoch [7/10], Loss: 3338.8840\n",
            "Epoch [8/10], Loss: 2357.4307\n",
            "Epoch [9/10], Loss: 1028.2095\n",
            "Epoch [10/10], Loss: 450.7536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the trained model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    test_accuracy = accuracy_score(y_test, predicted)\n",
        "\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3mGDFlybH6-",
        "outputId": "718fb601-3357-40fa-d110-223fd282ee9e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 68.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Measuring the size of the original model\n",
        "torch.save(model.state_dict(), \"original_model.pth\")\n",
        "original_model_size = os.path.getsize(\"original_model.pth\")\n",
        "print(f\"Original Model Size: {original_model_size / 1024:.2f} KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmjVvmw3bKfe",
        "outputId": "ad8625f7-c403-467b-8c7b-3ad2d51d978b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Size: 32.19 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4: Quantization Function\n",
        "def quantize_model(model, scale_factor=2 ** 7):\n",
        "    # Copy the model to avoid modifying the original\n",
        "    quantized_model = LogisticRegressionModel(input_dim, output_dim)\n",
        "    quantized_model.load_state_dict(model.state_dict())\n",
        "\n",
        "    # Quantize the weights to 8-bit\n",
        "    with torch.no_grad():\n",
        "        for param in quantized_model.parameters():\n",
        "            param.data = torch.round(param.data * scale_factor) / scale_factor\n",
        "    return quantized_model"
      ],
      "metadata": {
        "id": "jzsxwmALbMrw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 5: Inference Function for the Quantized Model\n",
        "def inference(model, X):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    return predicted"
      ],
      "metadata": {
        "id": "kyS3qXx3bj1t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantizing the model\n",
        "quantized_model = quantize_model(model)\n",
        "quantize_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "8_9tlTKSbmgC",
        "outputId": "2c5c4c66-85f3-4d13-c0af-a314899bf538"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.quantize_model(model, scale_factor=128)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>quantize_model</b><br/>def quantize_model(model, scale_factor=2 ** 7)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-14-c87dcdfd699f&gt;</a>&lt;no docstring&gt;</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the quantized model size\n",
        "torch.save(quantized_model.state_dict(), \"quantized_model.pth\")\n",
        "quantized_model_size = os.path.getsize(\"quantized_model.pth\")\n",
        "print(f\"Quantized Model Size: {quantized_model_size / 1024:.2f} KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Ljdk5HbqNC",
        "outputId": "b04e47ec-e6f6-44fa-caa3-895bdf66ff8a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized Model Size: 32.20 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Measuring inference time for original and quantized models\n",
        "def measure_inference_time(model, X):\n",
        "    start_time = time.time()\n",
        "    _ = inference(model, X)\n",
        "    end_time = time.time()\n",
        "    return (end_time - start_time) * 1000  # Convert to milliseconds"
      ],
      "metadata": {
        "id": "3hap7XMTbtqA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_inference_time = measure_inference_time(model, X_test)\n",
        "original_inference_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDrZGEtEbw-I",
        "outputId": "05d2d9e5-ae56-482c-e993-324a025a5481"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34.60192680358887"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_inference_time = measure_inference_time(quantized_model, X_test)\n",
        "quantized_inference_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2FXGdwSbzE0",
        "outputId": "aabb9b0b-48a7-452c-bc7c-e2741a9946dd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.927915573120117"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the quantized model\n",
        "quantized_preds = inference(quantized_model, X_test)\n",
        "quantized_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1022d0Gib5H-",
        "outputId": "0422b453-1c75-4c51-a541-f01fd115426e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 5, 8,  ..., 5, 7, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_test_accuracy = accuracy_score(y_test, quantized_preds)\n",
        "quantized_test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua87opRXb67R",
        "outputId": "b0937e9a-2239-4cb5-c86c-427c6a6cac76"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6849166666666666"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 6: Comparison Results\n",
        "print(f\"Quantized Test Accuracy: {quantized_test_accuracy * 100:.2f}%\")\n",
        "print(f\"Original Inference Time: {original_inference_time:.2f} ms\")\n",
        "print(f\"Quantized Inference Time: {quantized_inference_time:.2f} ms\")\n",
        "print(f\"Original Model Size: {original_model_size / 1024:.2f} KB\")\n",
        "print(f\"Quantized Model Size: {quantized_model_size / 1024:.2f} KB\")\n",
        "print(f\"Original Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Quantized Test Accuracy: {quantized_test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFWhyfe7al9n",
        "outputId": "ccb41f58-0fb7-4048-b4e1-6efdac50ba0c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized Test Accuracy: 68.49%\n",
            "Original Inference Time: 34.60 ms\n",
            "Quantized Inference Time: 10.93 ms\n",
            "Original Model Size: 32.19 KB\n",
            "Quantized Model Size: 32.20 KB\n",
            "Original Test Accuracy: 68.51%\n",
            "Quantized Test Accuracy: 68.49%\n"
          ]
        }
      ]
    }
  ]
}